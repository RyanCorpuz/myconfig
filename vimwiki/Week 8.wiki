= Week 8 - Unsupervised Learning/Dimensionality Reduction =
DATE:  MON 07/13/2020

== Unsupervised Learning ==
Clustering Algorithm
	Examples:
		- Market segmentation
		- Social network analysis
		- Organize computing clusters
		- Astronomical data analysis

	K-Means Algorithm

	Optimization Objective
	
	Random Initialization
	
	Choosing the Number of Clusters


== Dimensionality Reduction ==
Motivation
	Data Compression
	
	Data Visualization

Principal Component Analysis
	Principal Component Analysis Problem Formulation
	
	Principal Component Analysis Algorithm
		Data Preprocessing
			- feature scaling
			- mean normalization
		
	X=[---x(m)'---]
	Sigma = 1/m*X'*X;
	[U,S,V] = svd(Sigma);
	Ureduce = U(:,1:k);
	z = x*Ureduce
	
Reconstruction from Compressed Representation
	x = Ureduce*z

Choosing the Number of Principal Components

Advice for Applying PCA
	Compression
		- Reduce memory/disk needed to store data
		- Speed up learning algorithm
	Visualization
		- K = 2 or K = 3

	Don't use PCA to prevent overfitting. BAD!
	Use regularization instead
	
	Run with original/raw data. Only if that doesn't do what you want, then implement PCA and consider using z (if too slow or memory constraint)
